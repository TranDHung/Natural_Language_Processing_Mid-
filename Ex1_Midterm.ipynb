{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "Ex1_Midterm.ipynb",
      "provenance": [],
      "collapsed_sections": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "code",
      "execution_count": 17,
      "metadata": {
        "id": "IsTRFLfljLu_"
      },
      "outputs": [],
      "source": [
        "import nltk, re, string\n",
        "from nltk import word_tokenize, sent_tokenize\n",
        "from nltk.util import ngrams\n",
        "from collections import Counter"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "nltk.download('punkt')"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "IrcaVeWG8NK6",
        "outputId": "98734603-41a7-43ee-c142-09d4a41ce73b"
      },
      "execution_count": 18,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[nltk_data] Downloading package punkt to /root/nltk_data...\n",
            "[nltk_data]   Package punkt is already up-to-date!\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "True"
            ]
          },
          "metadata": {},
          "execution_count": 18
        }
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 19,
      "metadata": {
        "id": "5_xUW8Vm5IuH"
      },
      "outputs": [],
      "source": [
        "string.punctuation = string.punctuation +'“'+'”'+'-'+'’'+'‘'+'—'\n",
        "string.punctuation = string.punctuation.replace('.', '')\n",
        "\n",
        "file = open('/content/corpus.txt', encoding = 'utf8').read()\n",
        "\n",
        "file_nl_removed = \"\"\n",
        "for line in file:\n",
        "  line_nl_removed = line.replace(\"\\n\", \" \")      #removes newlines\n",
        "  file_nl_removed += line_nl_removed\n",
        "file_p = \"\".join([char for char in file_nl_removed if char not in string.punctuation])"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# get sentences from the corpus\n",
        "sents = file_p.split('. ')\n",
        "print(sents[:5])"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Ur4Ldv6T6ImC",
        "outputId": "9c19a016-f597-400f-ea10-1531b5f2a4ec"
      },
      "execution_count": 20,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "['When Mary Lennox was sent to Misselthwaite Manor to live with her uncle everybody said she was the most disagreeablelooking child ever seen', 'It was true too', 'She had a little thin face and a little thin body thin light hair and a sour expression', 'Her hair was yellow and her face was yellow because she had been born in India and had always been ill in one way or another', 'Her father had held a position under the English Government and had always been busy and ill himself and her mother had been a great beauty who cared only to go to parties and amuse herself with gay people']\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "sentences=[]\n",
        "all_tokens_count=0\n",
        "for sent in sents:\n",
        "    tokens = nltk.word_tokenize(sent.lower())\n",
        "    all_tokens_count += len(tokens)\n",
        "    sentences.append(['<s>']+tokens+['</s>'])\n",
        "print(\"The number of tokens is\",all_tokens_count)\n",
        "print(\"The number of sentences is\",len(sentences))\n",
        "print(sentences[:5])"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "W6oUDkdt8Hxb",
        "outputId": "0b2a4b6a-85f0-4693-ef45-6419d9986e42"
      },
      "execution_count": 21,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "The number of tokens is 198455\n",
            "The number of sentences is 12207\n",
            "[['<s>', 'when', 'mary', 'lennox', 'was', 'sent', 'to', 'misselthwaite', 'manor', 'to', 'live', 'with', 'her', 'uncle', 'everybody', 'said', 'she', 'was', 'the', 'most', 'disagreeablelooking', 'child', 'ever', 'seen', '</s>'], ['<s>', 'it', 'was', 'true', 'too', '</s>'], ['<s>', 'she', 'had', 'a', 'little', 'thin', 'face', 'and', 'a', 'little', 'thin', 'body', 'thin', 'light', 'hair', 'and', 'a', 'sour', 'expression', '</s>'], ['<s>', 'her', 'hair', 'was', 'yellow', 'and', 'her', 'face', 'was', 'yellow', 'because', 'she', 'had', 'been', 'born', 'in', 'india', 'and', 'had', 'always', 'been', 'ill', 'in', 'one', 'way', 'or', 'another', '</s>'], ['<s>', 'her', 'father', 'had', 'held', 'a', 'position', 'under', 'the', 'english', 'government', 'and', 'had', 'always', 'been', 'busy', 'and', 'ill', 'himself', 'and', 'her', 'mother', 'had', 'been', 'a', 'great', 'beauty', 'who', 'cared', 'only', 'to', 'go', 'to', 'parties', 'and', 'amuse', 'herself', 'with', 'gay', 'people', '</s>']]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# counting 1-gram \n",
        "counter_unigram=Counter()\n",
        "for sent in sentences:\n",
        "    counter_unigram.update(sent)\n",
        "V=len(counter_unigram)\n",
        "print('V =',V)\n",
        "n=0\n",
        "for gram in counter_unigram:\n",
        "    n+=counter_unigram[gram]\n",
        "n=n-counter_unigram['<s>']-counter_unigram['</s>']\n",
        "print('n =',n)\n",
        "print(counter_unigram['the'])\n",
        "print(counter_unigram['he'])"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "BLp9kRaD_JZa",
        "outputId": "55e57404-19f1-44b9-dc5c-468f54095937"
      },
      "execution_count": 22,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "V = 8635\n",
            "n = 198455\n",
            "9584\n",
            "4105\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# counting bi-gram\n",
        "bi_grams=[]\n",
        "for sent in sentences:\n",
        "    bi_grams.extend(ngrams(sent,2))\n",
        "\n",
        "print(len(bi_grams))\n",
        "\n",
        "for i in range(3):\n",
        "    print(bi_grams[i])\n",
        "\n",
        "freq_bi = nltk.FreqDist(bi_grams)\n",
        "print (\"Most common bigrams: \", freq_bi.most_common(5))\n",
        "counter_bigram = Counter(bi_grams)\n",
        "V2 = len(counter_bigram)\n",
        "print('V=',V2)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "MwPuAgpg_tEl",
        "outputId": "614320c5-ce43-40c0-ea51-af8f81db8576"
      },
      "execution_count": 23,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "210662\n",
            "('<s>', 'when')\n",
            "('when', 'mary')\n",
            "('mary', 'lennox')\n",
            "Most common bigrams:  [(('<s>', 'the'), 1307), (('<s>', 'he'), 1133), (('<s>', 'i'), 1118), (('in', 'the'), 806), (('<s>', 'she'), 790)]\n",
            "V= 62373\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# counting tri-gram \n",
        "tri_grams=[]\n",
        "for sent in sentences:\n",
        "    tri_grams.extend(ngrams(sent,3))\n",
        "\n",
        "print(len(tri_grams))\n",
        "\n",
        "for i in range(3):\n",
        "    print(tri_grams[i])\n",
        "\n",
        "freq_tri = nltk.FreqDist(tri_grams)\n",
        "print (\"Most common trigrams: \", freq_tri.most_common(5))\n",
        "counter_trigram = Counter(tri_grams)\n",
        "V = len(counter_trigram)\n",
        "print('V =',V)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "WNvf92ZwA3BL",
        "outputId": "8671938b-49c6-4acf-8265-ff41fa04186d"
      },
      "execution_count": 24,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "198455\n",
            "('<s>', 'when', 'mary')\n",
            "('when', 'mary', 'lennox')\n",
            "('mary', 'lennox', 'was')\n",
            "Most common trigrams:  [(('<s>', 'it', 'was'), 208), (('<s>', 'he', 'was'), 157), (('<s>', 'she', 'was'), 121), (('<s>', 'he', 'had'), 109), (('he', 'said', '</s>'), 103)]\n",
            "V = 115978\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#Build language model with Bi-gram and Lapace smoothing.\n",
        "            \n",
        "set_bi_grams = set(bi_grams)                   \n",
        "bi_dict={}\n",
        "alpha = 0.001\n",
        "\n",
        "for gram in set_bi_grams:\n",
        "    key = gram[0]\n",
        "    prob = (counter_bigram[(gram[0],gram[1])]+alpha)/(counter_unigram[(gram[0])]+alpha*V2) #add lapace smoothing\n",
        "    if key in bi_dict.keys():\n",
        "        bi_dict[key][gram[1]] = prob\n",
        "    else:\n",
        "        bi_dict[key]={gram[1]:prob}"
      ],
      "metadata": {
        "id": "BeHegTz_UYjr"
      },
      "execution_count": 25,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#Build language model with Tri-gram and Lapace smoothing.\n",
        "            \n",
        "set_tri_grams = set(tri_grams)                   \n",
        "tri_dict={}\n",
        "\n",
        "for gram in set_tri_grams:\n",
        "    key=(gram[0],gram[1])\n",
        "    prob = (counter_trigram[(gram[0],gram[1],gram[2])]+alpha)/(counter_bigram[(gram[0],gram[1])]+alpha*V) #add lapace smoothing\n",
        "    if key in tri_dict.keys():\n",
        "        tri_dict[key][gram[2]] = prob\n",
        "    else:\n",
        "        tri_dict[key]={gram[2]:prob}"
      ],
      "metadata": {
        "id": "ukYhkIJcAUZu"
      },
      "execution_count": 26,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# predict next word by bi-gram\n",
        "def predict_word_bigram(sent):\n",
        "  res = ''\n",
        "  tokens = word_tokenize(sent.lower())\n",
        "  tokens = ['<s>']+tokens\n",
        "  i=len(tokens)-1\n",
        "  key=(tokens[i])\n",
        "  if key in bi_dict.keys():\n",
        "    sorted_dict=sorted(bi_dict[key],key=bi_dict[key].__getitem__,reverse=True)\n",
        "    res = sorted_dict[0]\n",
        "  else:\n",
        "    res = 'Not found'\n",
        "  return res"
      ],
      "metadata": {
        "id": "--6M7JyNVtyX"
      },
      "execution_count": 27,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# predict next word by tri-gram\n",
        "def predict_word_trigram(sent):\n",
        "  res = ''\n",
        "  tokens = word_tokenize(sent.lower())\n",
        "  tokens = ['<s>']+tokens\n",
        "  i=len(tokens)-1\n",
        "  key=(tokens[i-1],tokens[i])\n",
        "  if key in tri_dict.keys():\n",
        "    sorted_dict=sorted(tri_dict[key],key=tri_dict[key].__getitem__,reverse=True)\n",
        "    res = sorted_dict[0]\n",
        "  else:\n",
        "    res = 'Not found'\n",
        "  return res"
      ],
      "metadata": {
        "id": "lDFASwmgJQRV"
      },
      "execution_count": 28,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "print(\"Tri-gram: \",predict_word_trigram('Let me help you'))\n",
        "print(\"Bi-gram: \",predict_word_bigram('Let me help you'))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "0l-aH9WFbDAV",
        "outputId": "7cc2d3d1-d1bc-4294-8f65-ff69e2eaa9ae"
      },
      "execution_count": 29,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Tri-gram:  with\n",
            "Bi-gram:  are\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# read test file for testing\n",
        "filename='/content/Ex1_test.txt'\n",
        "test=[]\n",
        "with open(filename,'r') as f:\n",
        "    for s in f:\n",
        "        test.append(s.strip())\n",
        "print(len(test))\n",
        "print(test[:5]) "
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "UvpbCEaDMn1m",
        "outputId": "9a35dba8-64bf-45f0-bf70-9b131f41b000"
      },
      "execution_count": 30,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "100\n",
            "['Let me help you [X] your baggage.', 'More RVs were seen in the storage lot than [X] the campground.', 'I was offended [X] the suggestion that my baby brother was a jewel thief.', 'She lived [X] Monkey Jungle Road and that seemed to explain all of her strangeness.', \"He wasn't bitter that she had moved [X] but from the radish.\"]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# read check file for checking\n",
        "filename='/content/Ex1_check.txt'\n",
        "check=[]\n",
        "with open(filename,'r') as f:\n",
        "    for s in f:\n",
        "        check.append(s.strip())\n",
        "print(len(check))\n",
        "print(check[:5]) "
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "zQvuIE-KcAK4",
        "outputId": "78723345-5024-40c4-ec5a-d33ae5a1ea6a"
      },
      "execution_count": 31,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "100\n",
            "['with', 'at', 'by', 'on', 'on']\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Cal the accuracy of the language model on 100 sentences\n",
        "count1 = 0\n",
        "count2 = 0\n",
        "for i in range(len(test)):\n",
        "  seq=test[i][:test[i].find(\" [X] \")]\n",
        "  res1 = predict_word_bigram(seq)\n",
        "  res2 = predict_word_trigram(seq)\n",
        "  if res1 == check[i]:\n",
        "    count1 += 1\n",
        "  if res2 == check[i]:\n",
        "    count2 += 1\n",
        "\n",
        "print(\"The accuracy of bi-grams on 100 sentences:\",count1/len(test))\n",
        "print(\"The accuracy of tri-grams on 100 sentences:\",count2/len(test))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "XFimyvLNZsgf",
        "outputId": "0e84bab8-1682-4ee0-c40f-5ad18fde26d9"
      },
      "execution_count": 32,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "The accuracy of bi-grams on 100 sentences: 0.51\n",
            "The accuracy of tri-grams on 100 sentences: 0.9\n"
          ]
        }
      ]
    }
  ]
}